import asyncio
import logging
import os
import re

from config import load_config, Config
from db import init_db, get_paused
from telegram_bot import build_app, send_to_owner
from scheduler import make_scheduler, add_digest_jobs
from digest import run_digest, build_daily_stats_text


class RedactTelegramBotTokenFilter(logging.Filter):
    """
    Redacts Telegram bot token from URLs like:
    https://api.telegram.org/bot<token>/method
    """
    _re = re.compile(r"(https://api\.telegram\.org/bot)(\d+:[A-Za-z0-9_-]+)(/)")

    def filter(self, record: logging.LogRecord) -> bool:
        try:
            msg = record.getMessage()
        except Exception:
            return True

        if msg:
            redacted = self._re.sub(r"\1[REDACTED]\3", msg)
            if redacted != msg:
                # Overwrite message safely
                record.msg = redacted
                record.args = ()
        return True


def setup_logging(level: str) -> None:
    logging.basicConfig(
        level=getattr(logging, level.upper(), logging.INFO),
        format="%(asctime)s %(levelname)s %(name)s: %(message)s",
    )

    # 1) Redact Telegram token in ANY log line (including from httpx/httpcore libs)
    logging.getLogger().addFilter(RedactTelegramBotTokenFilter())

    # 2) Optional: reduce noisy HTTP client logs (prevents full URL logging)
    # You can change WARNING -> ERROR if you want even less noise.
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("httpcore").setLevel(logging.WARNING)

    # Optional: python-telegram-bot can also be chatty depending on config
    # Keep bot logs, but don't spam with low-level details
    logging.getLogger("telegram").setLevel(logging.INFO)


async def main_async():
    cfg: Config = load_config()
    setup_logging(cfg.log_level)
    init_db()

    # Ensure TZ for APScheduler and logs
    os.environ["TZ"] = cfg.tz

    app = build_app(cfg)

    scheduler = make_scheduler(cfg.tz)

    last_digest_hour = max(cfg.schedule_hours) if cfg.schedule_hours else 18

    async def scheduled_digest_job(run_hour: int):
        if get_paused():
            logging.getLogger(__name__).info("Paused; skipping scheduled digest.")
            return
        try:
            text, total, failed = run_digest(cfg)
            await send_to_owner(app, cfg, text)
            await send_to_owner(app, cfg, f"Авто-дайджест отправлен. Писем: {total}, не обработано: {failed}.")
            if run_hour == last_digest_hour:
                await send_to_owner(app, cfg, build_daily_stats_text(cfg))
        except Exception as e:
            logging.getLogger(__name__).exception("Scheduled digest failed")
            await send_to_owner(app, cfg, f"Ошибка авто-дайджеста: {e}")

    add_digest_jobs(scheduler, cfg.schedule_hours, scheduled_digest_job)
    scheduler.start()

    # Start bot (long polling)
    await app.initialize()
    await app.start()
    await app.updater.start_polling(drop_pending_updates=True)

    # Keep running
    try:
        while True:
            await asyncio.sleep(3600)
    finally:
        await app.updater.stop()
        await app.stop()
        await app.shutdown()


if __name__ == "__main__":
    asyncio.run(main_async())
